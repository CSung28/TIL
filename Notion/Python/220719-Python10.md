# 7/19(Tue) Python Day 10(Online)(EDA Practices)

# **탐색적 데이터 분석이란?**

## **EDA(Exploratory Data Analysis):
데이터에서 분석에 필요한 여러가지 통계랑을 계산하고, 
시각화를 통해서 이를 확인하는 작업**

## **RECAP**

- 탐색적 데이터 분석(Exploratory Data Analysis, EDA)는 데이터와 친해지는 과정이다.
- 분석을 하면서 데이터에서 확인하고 싶은 정보들을 찾아가는 과정이다.
- 정답처럼 규칙처럼 정해진 프로세스는 따로 없고, 완전히 분석가들의 직관과 분석 프로세스에 따라 갈린다.
- 어떤 데이터를 사용하느냐에 따라서도 천차만별로 갈린다.
- 나만의 EDA Process를 구축하는 것이 Data Scientist로서의 역량이라고 볼 수 있습니다.

### **이제부터 하게 될 3가지 케이스에서 주요하게 생각해야 하는 건 다음과 같다.**

1. 해당 데이터를 보고 어떤 **insight**를 이끌어내고 싶은지? (분석의 목표)
2. 데이터에 대한 여러가지 특성을 어떻게 파악하는지? (분석 방법론)
3. 이때까지 배운 오픈소스 라이브러리들을 사용하여 EDA를 어떻게 수행하는지? 
(분석을 위한 프로그래밍)

## **Case 1. Starbucks Survey**

- 스타벅스 고객들의 이벤트 관련 설문에 응답한 데이터의 일부를 가지고 데이터를 전처리, 시각화 해본다.
- 해당 데이터에서 고객들이 이벤트에 대한 응답을 어떻게 하는지 찾고 고객 프로모션 개선 방안에 대한 인사이트를 찾는다.

### **(1) Data Description**

**→ *왜 읽어야 할까?*** 

Description에는 각 table이 가지고 있는 정보들을 알 수 있고 이에 근거해 어떤 자료들이 있는지, 어떤 인사이트를 뽑을 수 있는지 생각해볼 수 있기 때문이다.

- **Description**
    1. Profile table
    
    > profile 데이터는 설문에 참여한 스타벅스 회원에 관련된 정보가 담겨 있습니다.
    > 
    
    > "Dimesional data about each person, including their age, salary, and gender. There is one unique customer for each record."
    > 
    1. transcript
    
    > 이벤트에 참여한 실제 유저들의 응답이 기록되어 있습니다.
    > 
    
    > "Records show the different steps of promotional offers that a customer received. The different values of receiving a promotion are receiving, viewing, and completing. You also see the different transactions that a person made in the time since he became a customer. With all records, you see the day that they interacted with Starbucks and the amount that it is worth."
    > 
    1. portfoilo
    
    > 이벤트를 운영했던 내역에 관한 정보가 담겨 있습니다.
    > 
    
    > "Information about the promotional offers that are possible to receive, and basic information about each one including the promotional type, duration of the promotion, reward, and how the promotion was distributed to customers."
    > 

### **(2) 라이브러리 및 데이터 로드**

```python
# 데이터 분석 필수 라이브러리 4종 세트 불러오기
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

-----------------------------------------------------
# Starbucks Customer Data 폴더안에 있는 데이터 3개를 불러오기
# .drop(columns = ['Unnamed: 0']) -> Unnamed: 0 column을 지운다.
transcript = pd.read_csv('C:\\Users\\X1Carbon\\Desktop\\python\\data\\Starbucks\\transcript.csv').drop(columns = ['Unnamed: 0'])
profile = pd.read_csv('C:\\Users\\X1Carbon\\Desktop\\python\\data\\Starbucks\\profile.csv').drop(columns = ['Unnamed: 0'])
portfolio = pd.read_csv('C:\\Users\\X1Carbon\\Desktop\\python\\data\\Starbucks\\portfolio.csv').drop(columns = ['Unnamed: 0'])

# 후에 잘 불러져왔는지 보기 위해서 table 변수 이름을 쳐보거나 **.head()**함수를 사용
```

### **(3) 데이터 전처리**

- 결측치가 존재하는 데이터를 찾아서 결측치를 처리해준다.

```python
# 각 데이터에 결측치가 있는지 확인한다.
# info() 함수에는 다양한 값을 알려준다.
profile.info() # 17000 - 14825 = 2175(null-count)가 있음
>>>
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 17000 entries, 0 to 16999
Data columns (total 5 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   gender            14825 non-null  object 
 1   age               17000 non-null  int64  
 2   id                17000 non-null  object 
 3   became_member_on  17000 non-null  int64  
 4   income            14825 non-null  float64
dtypes: float64(1), int64(2), object(2)
memory usage: 664.2+ KB

-----------------------------------------------------
# 결측치를 포함하는 데이터들은 어떤 데이터들인지 확인한다.
# any(axis= 1): profile에 한개라도 널이 있는 로우파일을 출력해줘라는 의미
nulls = profile[profile.isnull().any(axis = 1)]

# gender, age 등은 column을 뜻함
nulls.gender.value_counts()

-----------------------------------------------------
# 결측치를 처리해준다. 
# 평균과 같은 통계량으로 채워주거나, 버린다.
profile = profile.dropna()
profile.info()
>>>
<class 'pandas.core.frame.DataFrame'>
Int64Index: 14825 entries, 1 to 16999
Data columns (total 5 columns):
 #   Column            Non-Null Count  Dtype         
---  ------            --------------  -----         
 0   gender            14825 non-null  object        
 1   age               14825 non-null  int64         
 2   id                14825 non-null  object        
 3   became_member_on  14825 non-null  datetime64[ns]
 4   income            14825 non-null  float64       
dtypes: datetime64[ns](1), float64(1), int64(1), object(2)
memory usage: 694.9+ KB
```

### **(4) profile 데이터 분석**

- 설문에 참여한 사람 중, 정상적인 데이터로 판단된 데이터에 대한 분석을 수행한다.
- 각 column마다 원하는 통계량을 찾은 뒤, 해당 통계량을 멋지게 시각화해줄 plot을 seaborn에서 가져와 구현한다.

```python
# profile의 became_member_on 데이터를 시간 정보로 변환해준다.
# became_member_on이 int64 형식이기 때문!
# astype(str)을 통해 string으로 변경한 뒤 
# 뒤의 포맷으로 다시 datetime 형식으로 바꿔준다
profile.became_member_on = pd.to_datetime(profile.became_member_on.astype(str), format='%Y%m%d')
profile.became_member_on
>>>
1       2017-07-15
3       2017-05-09
           ...    
16998   2016-03-07
16999   2017-07-22
Name: became_member_on, Length: 14825, dtype: **datetime64[ns]**

-----------------------------------------------------
profile.info()
>>>
<class 'pandas.core.frame.DataFrame'>
Int64Index: 14825 entries, 1 to 16999
Data columns (total 5 columns):
 #   Column            Non-Null Count  Dtype         
---  ------            --------------  -----         
 0   gender            14825 non-null  object        
 1   age               14825 non-null  int64         
 2   id                14825 non-null  object        
 3   became_member_on  14825 non-null  datetime64[ns]
 4   income            14825 non-null  float64       
dtypes: datetime64[ns](1), float64(1), int64(1), object(2)
memory usage: 694.9+ KB
```

<aside>
✅ **(4)-1. 성별에 대한 분석**

```python
# countplot으로 성별에 대한 분석을 해보자
plt.figure(figsize=(8,6))
sns.countplot(data = profile, x = 'gender', palette = 'Set2')
plt.show()

-----------------------------------------------------
# 좀 더 구체적인 number로 알고 싶다면
profile.gender.value_counts()
>>>
M    8484
F    6129
O     212
Name: gender, dtype: int64
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C.jpg)

```python
# pivot table로 구현해보기
pd.pivot_table(data = profile, index = 'gender', values = 'income')
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%201.jpg)

<aside>
💡 **Insight
1. 여성보다는 남성이 응답비율이 높은 것을 알 수 있음
2. O은 other를 의미하는 것으로 제 3의 성 등을 나타냄
→ data description 참고
3. pivot table을 보면 이벤트에 대답한 비율 내에서 여성의 income 평균이 더 높다.**

</aside>

</aside>

<aside>
✅ **(4)-2. 나이에 대한 분석**

```python
# countplot을 사용하여 분석해보자
plt.figure(figsize=(12,6))
sns.countplot(data = profile, x = 'age')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%202.jpg)

**→ 분석에 그다지 좋은 그래프가 아님**

- ***그렇다면 Histogram을 사용해보자!*
→** age같은 경우에는 전반적인 range가 18 ~ 101으로 크고 전체적인 연령대를 보기 위해서이다.

```python
plt.figure(figsize=(12,6))
sns.histplot(data = profile, x = 'age')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%203.jpg)

```python
# 약간의 변형
# bins -> 그래프의 출력되는 막대 등의 갯수를 조절한다.
plt.figure(figsize=(12,6))
sns.histplot(data = profile, x = 'age', bins = 15, hue = 'gender', multiple = 'stack')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%204.jpg)

</aside>

<aside>
✅ **(4)-3. 회원이 된 날짜에 대한 분석**

```python
# .dt.year: 날짜 형식 중에서 연도만 뽑혀나온다.
# .dt.month: 월만 뽑혀나온다.
profile['join_yr'] = profile.became_member_on.dt.year
profile['join_month'] = profile.became_member_on.dt.month
profile
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%205.jpg)

```python
# 연도별로 보기
plt.figure(figsize = (12, 6))
sns.countplot(data = profile, x = 'join_yr', palette = 'Set2')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%206.jpg)

```python
# profile의 join_month에서 value_counts의 인덱스와 값을 
# 각각 변수로 지정해준다.
x = profile.join_month.value_counts().index
y = profile.join_month.value_counts().values

-----------------------------------------------------
# 월별로 보기
plt.figure(figsize = (12, 6))

# 정렬하기 -> x, y를 함께 써주어야함!
sns.barplot(data = profile, x= x, y =y, order = x)
# sns.countplot(data = profile, y = 'join_month')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%207.jpg)

</aside>

<aside>
✅ **(4)-4. 수입에 대한 분석**

```python
plt.figure(figsize = (8,6))
sns.histplot(data = profile, y = 'income', hue = 'gender')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%208.jpg)

</aside>

<aside>
✅ **(4)-5. profile 데이터에 대한 상관관계 분석**

```python
plt.figure(figsize = (6, 6))
sns.heatmap(data = profile.corr(), square = True, annot = True)
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%209.jpg)

</aside>

### **(5) transcript에 대한 분석**

- 각 column마다 원하는 통계량을 찾은 뒤, 해당 통계량을 멋지게 시각화해줄 plot을 seaborn에서 가져와 구현한다.
- *person*과 *values column*은 분석 대상에서 제외한다.

<aside>
✅ **(5)-1. event에 대한 분석**

```python
# transaction이 모든 것을 다 포함하는 것이고
# 굳이 자르면 offer received, viewed, completed로 나눌 수 있는 것이다.
plt.figure(figsize = (8, 6))
sns.countplot(data = transcript, x = 'event', palette = 'spring')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2010.jpg)

```python
# pivot table로 구현해보자
pd.pivot_table(data = transcript, index = 'event', values = 'time')
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2011.jpg)

</aside>

<aside>
✅ **(5)-2. time에 대한 분석**

```python
plt.figure(figsize = (8, 6))
sns.histplot(data = transcript, x = 'time')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2012.jpg)

```python
# 위의 그래프에서 튀는 부분들을 찾아보자
transcript.time.value_counts()[:6]

-----------------------------------------------------
# 위의 것의 index를 색출한다음 정렬한다.
sorted(transcript.time.value_counts()[:6].index)
>>> [0, 168, 336, 408, 504, 576]
# -> 24로 나누면 7, 14, ... 등의 값이 나옴

-----------------------------------------------------
temp = sorted(transcript.time.value_counts()[:6].index)
print(temp) 
for i in range(len(temp)-1):
    print(temp[i+1] - temp[i], end = ' ')
>>>
[0, 168, 336, 408, 504, 576] # 그래프에서 튀어올라온 애들
  168 168 72  96  72
# 7일 7일 3일 4일 3일
# 1주일마다 이벤트를 다시 뿌리지 않았을까 유추할 수 있음

-----------------------------------------------------
# 위의 튀어올라오는 애들을 뽑기 위한 indexing
temp_df = transcript.loc[transcript.time.isin(temp), :]
temp_df.time.value_counts()
>>>
408    17030
576    17015
504    16822
336    16302
168    16150
0      15561
Name: time, dtype: int64

-----------------------------------------------------
# countplot으로 시각화한 결과,
# offer를 받고 나서 연 사람이 가장 많았다.
plt.figure(figsize = (8, 6))
sns.countplot(data = temp_df, x = 'event', palette = 'Set2')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2013.jpg)

```python
plt.figure(figsize = (8, 6))
sns.countplot(data = temp_df, x = 'event', palette = 'Set2')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2014.jpg)

```python
plt.figure(figsize = (10, 8))
sns.countplot(data = temp_df, x = 'time', hue = 'event')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2015.jpg)

</aside>

## **Case 2. Kaggle Survey**

- Kaggle이라는 Data Science Community가 있습니다. Kaggle에서는 매년 Kaggle 사용자들을 중심으로 설문조사를 시행합니다. 해당 설문조사 결과는 전세계에 뛰어난 Data Scientist들이 어떻게 일하고 어떤 것들을 공부하고 있는지 알 수 있는 좋은 자료이다.
- 이번에 사용하는 데이터셋은 2021 Kaggle Machine Learning Survey 데이터셋을 사용 활동하는 Kaggler들에 대해 살펴보려고 한다.

### **(1) Data Description**

- 데이터의 첫번째 Row에는 각 질문이 어떤 것이었는지 대한 내용이 적혀있다.
- 해당 데이터가 어떻게 수집되었는지, 활용하려면 어떻게 해야하는지 관심 있는 분들은 해당 데이터셋을 다운로드 하면 supplementary_data 폴더에서 해당 내용을 활용할 수 있다.
- 아래 링크에서 데이터를 다운로드 받아봅시다. 해당 데이터셋을 받기 위해서는 Kaggle에 회원가입이 되어있어야 하며, 대회 규정에 대해 동의하여야 한다.

**Source : [https://www.kaggle.com/c/kaggle-survey-2021/data](https://www.kaggle.com/c/kaggle-survey-2021/data)**

### **(2) 라이브러리 및 데이터 불러오기**

```python
import numpy as np  
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns 

# 여기서 데이터프레임을 할 때 최대 100개까지 output을 보여준다.
pd.options.display.max_rows = 100

# 경고를 나오는 것을 무시해준다.
import warnings
warnings.filterwarnings('ignore')
```

```python
# 내가 저장한 폴더에서 데이터를 불러온다.
survey = pd.read_csv('C:\\Users\\X1Carbon\\Desktop\\python\\data\\kaggle-survey-2021-20220719T042145Z-001\\kaggle-survey-2021\\kaggle_survey_2021_responses.csv') 
survey
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2016.jpg)

### **(3) 데이터 전처리**

```python
# 불러온 dataframe의 정보를 요약 정보를 확인한다.
survey.info()
>>>
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 25974 entries, 0 to 25973
Columns: 369 entries, Time from Start to Finish (seconds) to Q38_B_OTHER
dtypes: object(369)
memory usage: 73.1+ MB
```

```python
# 함수를 작성해보세요.
# 그냥하면 row가 잘리기때문에 column으로 자르고 싶으면 loc 나 iloc
# 모든것에 대해 8개 잘라주세요
# null 값이 있는 것을 확인할 수 있음.
survey.iloc[:, :8].info()
>>>
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 25974 entries, 0 to 25973
Data columns (total 8 columns):
 #   Column                               Non-Null Count  Dtype 
---  ------                               --------------  ----- 
 0   Time from Start to Finish (seconds)  25974 non-null  object
 1   Q1                                   25974 non-null  object
 2   Q2                                   25974 non-null  object
 3   Q3                                   25974 non-null  object
 4   Q4                                   25974 non-null  object
 5   Q5                                   25974 non-null  object
 6   Q6                                   25974 non-null  object
 7   Q7_Part_1                            21861 non-null  object
dtypes: object(8)
memory usage: 1.6+ MB

# 해당 데이터셋은 column이 너무 많아 전체적인 정보를 확인하기 힘들다.
# 바로 null 값을 처리하기보다는 필요한 컬럼만 뽑아서 쓸 것이다.
```

### **(4) 한국사람 찾기**

```python
# 잘라온 데이터에서 한국은 어떤 텍스트로 표현이 되는지 찾아보자.
survey.Q3.value_counts()
survey.Q3.unique()
>>>
India                                                   7434
United States of America                                2650
Other                                                   1270
Japan                                                    921
China                                                    814
Brazil                                                   751
Russia                                                   742
Nigeria                                                  702
United Kingdom of Great Britain and Northern Ireland     550
Pakistan                                                 530
Egypt                                                    482
Germany                                                  470
Spain                                                    454
Indonesia                                                444
Turkey                                                   416
France                                                   401
South Korea                                              359
...
Belarus                                                   51
Austria                                                   51
Ecuador                                                   50
Denmark                                                   48
Uganda                                                    47
Kazakhstan                                                45
Norway                                                    45
Algeria                                                   44
Ethiopia                                                  43
Iraq                                                      43
In which country do you currently reside?                  1
Name: Q3, dtype: int64

------------------------------------------------------------
# masking을 하는 것임
survey.Q3.str.contains('Korea') 
>>>
0        False
1        False
2        False
3        False
4        False
         ...  
25969    False
25970    False
25971    False
25972    False
25973    False
Name: Q3, Length: 25974, dtype: bool

------------------------------------------------------------
survey의 Q3열에서 Korea라는 str을 포함하고 있는 모든 row
survey.loc[survey.Q3.str.contains('Korea'), 'Q3']
>>>
276      South Korea
373      South Korea
410      South Korea
482      South Korea
492      South Korea
            ...     
25497    South Korea
25628    South Korea
25842    South Korea
25867    South Korea
25968    South Korea
Name: Q3, Length: 359, dtype: object
```

```python
# 한국사람을 불러와보자!
korean = survey.loc[survey.Q3 == 'South Korea']
korean
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2017.jpg)

<aside>
✅ **(4)-1. 성별에 대한 분석**

```python
# 성별을 분석하기 위해 column의 countplot을 그려보자.
plt.figure(figsize = (8, 6))
sns.countplot(data = korean, x = 'Q2')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2018.jpg)

</aside>

<aside>
✅ **(4)-2. 최종학력에 대한 분석**

```python
# 한국인의 최종학력에 해당하는 column의 countplot을 그려보자.
plt.figure(figsize = (8, 6))
sns.countplot(data = korean, y = 'Q4', palette = 'Set2')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2019.jpg)

```python
# 전체에 대한 것
plt.figure(figsize = (8, 6))
sns.countplot(data = survey, y = 'Q4', palette = 'Set2')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2020.jpg)

</aside>

### **(5) 각 나라별 학력 통계 계산하기**

<aside>
✅ **(5)-1. pivot table 만들기**

```python
# 학력별로 카운트한거라 의미가 없음
countries = pd.pivot_table(data = survey, index = 'Q3', values = 'Q4', aggfunc = 'count')
countries
```

![중략된 것임](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2021.jpg)

중략된 것임

```python
# aggfuc = Q4의 value들을 count해서 보여주세요
# fill_value = 0 이면 NaN 값을 0으로 바꿔준다.
countries = pd.pivot_table(data = survey.loc[1:, ['Q3', 'Q4']], index = 'Q3', columns = 'Q4', aggfunc = {'Q4': 'count'}, fill_value = 0)
countries
```

![중략된 것임](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2022.jpg)

중략된 것임

</aside>

<aside>
✅ **(5)-2. 특정 국가 가져오기**

```python
# 미국과 캐나다를 가져와보자
print(countries.loc['United States of America'])
print(countries.loc['Canada'])
>>>
    Q4                                                               
Q4  Bachelor’s degree                                                     714
    Doctoral degree                                                       436
    I prefer not to answer                                                 30
    Master’s degree                                                      1235
    No formal education past high school                                   18
    Professional doctorate                                                 45
    Some college/university study without earning a bachelor’s degree     172
Name: United States of America, dtype: int64
    Q4                                                               
Q4  Bachelor’s degree                                                    104
    Doctoral degree                                                       57
    I prefer not to answer                                                 5
    Master’s degree                                                      130
    No formal education past high school                                   3
    Professional doctorate                                                 3
    Some college/university study without earning a bachelor’s degree     29
Name: Canada, dtype: int64

------------------------------------------------------------
# 또는 display 함수를 활용
usa = countries.loc['United States of America']
canada = countries.loc['Canada']
display(usa)
display(canada)
>>> # 위와 동일한 값 출력
```

```python
# display() 를 bar로 보여주는 것도 가능하다.
display(usa.plot(kind = 'barh'))
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2023.jpg)

```python
# subplot을 이용해보자!
plt.subplot(2, 1, 1)
usa.plot(kind = 'barh')
plt.title('Final educated level of formal educaiton in USA & Canada')
plt.subplot(2, 1, 2)
display(canada.plot(kind = 'barh'))
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2024.jpg)

</aside>

### **(6) 프로그래밍 언어 선호도 분석**

<aside>
✅ **(6)-1. 프로그래밍 언어 선호도를 포함하는 column들을 불러오기**

```python
survey.Q7_Part_1[0]
# Part_2, Part_3 ... 쭉쭉쭉
>>>
# 어떤 프로그래밍 언어를 선호하는가에 대해 python을 선택한 것
'What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python'

------------------------------------------------------------
survey.columns.str.startswith('Q7') # -> masking
>>>
array([False, False, False, False, False, False, False,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, F
       ... False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
```

```python
Q7_columns = survey.columns[survey.columns.str.startswith('Q7')]
survey[['Q3'] + list(Q7_columns)]
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2025.jpg)

</aside>

<aside>
✅ **(6)-2. 언어별 정보가 합쳐진 DataFrame 만들기**

```python
q7_list = []

# iterrows()는 컬럼별로 나오는 걸 로우별로 나오게 해줌
# _, row는 앞에는 쓸데없게 나오거나 출력이 두개 되는데 앞에것을 쓰지 않겠다는 의미
for _, row in survey[Q7_columns][:3].iterrows():
    print(row)
>>>
Q7_Part_1     What programming languages do you use on a reg...
Q7_Part_2     What programming languages do you use on a reg...
Q7_Part_3     What programming languages do you use on a reg...
Q7_Part_4     What programming languages do you use on a reg...
Q7_Part_5     What programming languages do you use on a reg...
Q7_Part_6     What programming languages do you use on a reg...
Q7_Part_7     What programming languages do you use on a reg...
Q7_Part_8     What programming languages do you use on a reg...
Q7_Part_9     What programming languages do you use on a reg...
Q7_Part_10    What programming languages do you use on a reg...
Q7_Part_11    What programming languages do you use on a reg...
Q7_Part_12    What programming languages do you use on a reg...
Q7_OTHER      What programming languages do you use on a reg...
Name: 0, dtype: object
Q7_Part_1     Python
Q7_Part_2          R
Q7_Part_3        NaN
Q7_Part_4        NaN
Q7_Part_5        NaN
Q7_Part_6        NaN
Q7_Part_7        NaN
Q7_Part_8        NaN
Q7_Part_9        NaN
Q7_Part_10       NaN
Q7_Part_11       NaN
Q7_Part_12       NaN
Q7_OTHER         NaN
Name: 1, dtype: object
Q7_Part_1      NaN
Q7_Part_2      NaN
Q7_Part_3      SQL
Q7_Part_4        C
Q7_Part_5      C++
Q7_Part_6     Java
Q7_Part_7      NaN
Q7_Part_8      NaN
Q7_Part_9      NaN
Q7_Part_10     NaN
Q7_Part_11     NaN
Q7_Part_12     NaN
Q7_OTHER       NaN
Name: 2, dtype: object

------------------------------------------------------------
# debug 하기 위해 3개만 봄
for _, row in survey[Q7_columns][:3].iterrows():
    # masking앞에 ~(물결)을 붙혀주면 반대의 의미가 된다!
    print(row[~row.isnull()])
>>>
Q7_Part_1     What programming languages do you use on a reg...
Q7_Part_2     What programming languages do you use on a reg...
Q7_Part_3     What programming languages do you use on a reg...
Q7_Part_4     What programming languages do you use on a reg...
Q7_Part_5     What programming languages do you use on a reg...
Q7_Part_6     What programming languages do you use on a reg...
Q7_Part_7     What programming languages do you use on a reg...
Q7_Part_8     What programming languages do you use on a reg...
Q7_Part_9     What programming languages do you use on a reg...
Q7_Part_10    What programming languages do you use on a reg...
Q7_Part_11    What programming languages do you use on a reg...
Q7_Part_12    What programming languages do you use on a reg...
Q7_OTHER      What programming languages do you use on a reg...
Name: 0, dtype: object
Q7_Part_1    Python
Q7_Part_2         R
Name: 1, dtype: object
Q7_Part_3     SQL
Q7_Part_4       C
Q7_Part_5     C++
Q7_Part_6    Java
Name: 2, dtype: object

------------------------------------------------------------
# 인덱싱을 질문만 제거하고([1: ]) 
q7_list = []
for _, row in survey[Q7_columns][1:].iterrows():
    # masking앞에 ~(물결)을 붙혀주면 반대의 의미가 된다!
    # print(row[~row.isnull()].values) # 각 row별로 응답한 정보만 리스트로 출력.
    q7_list.append(row[~row.isnull()].values)
    
q7_list
>>>
[array(['Python', 'R'], dtype=object),
 array(['SQL', 'C', 'C++', 'Java'], dtype=object),
 array(['Python', 'C++', 'Java'], dtype=object),
 array(['Python'], dtype=object),
 array(['Python', 'C', 'MATLAB'], dtype=object),
 array(['Python'], dtype=object),
 array(['C++', 'Java', 'Javascript'], dtype=object),
 array(['Python'], dtype=object),
 array(['Python', 'SQL'], dtype=object),
 array(['Python', 'SQL'], dtype=object), ...(중략)

------------------------------------------------------------
# survey 테이블에 q7_list의 값을 넣어준다.
survey['PL'] = ['PL'] + q7_list
survey
```

![제목 없음2.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C2.jpg)

</aside>

<aside>
✅ **(6)-3. 한국인 응답자의 데이터만 뽑아보자**

```python
korean = survey.loc[survey.Q3 == 'South Korea', ['Q3'] + list(Q7_columns)]
korean
```

![제목 없음2.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C2%201.jpg)

### **countplot 그리기**

```python
# 인덱싱을 질문만 제거하고([1: ]) 
q7_list = []
 
for _, row in korean[Q7_columns][1:].iterrows():
# LM님 Comment
# 강의를 다시 확인해보니, 강사님께서 .tolist()를 추가하셨더라구요. 추가하면 정상 실행됩니다.
    q7_list.append(row[~row.isnull()].values.tolist())  

q7_list
>>>
[['Python', 'SQL', 'Java', 'Javascript'],
 ['Python'],
 ['Java', 'Javascript'],
 ['Python', 'C', 'C++'],
 ['Python'],
 ['MATLAB'],
 ['Python', 'R'],
 ['Python', 'R', 'Javascript'], ... (중략)
```

```python
# x축을 나이대 별로 정렬하여 countplot을 출력해보세요.
from collections import Counter

q7_data = []

for row in q7_list:
    q7_data += row
    

counter = Counter(q7_data)

df = pd.DataFrame({'Languages' : counter.keys(), 'Count' : counter.values()})
df
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2026.jpg)

```python
plt.figure(figsize = (6, 8))
sns.barplot(data = df, x = 'Count', y = 'Languages')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2027.jpg)

</aside>

## **Case 3. 공공데이터를 이용한 카페 상권분석**

- 공공데이터포털(data.go.kr)에 있는 다양한 데이터 중에 카페(라는 업종 분류)들에 대해서 
현황을 조사하려고 한다.
- **명시사항**
    1. 전국 카페 데이터를 모두 수집해야한다.
    2. 지역별 or 브랜드별 점포 현황을 확인한다.
    3. 분석 결과를 시각화 한다.
    

### **(1) 데이터 불러오기**

```python
# 다운로드 받은 데이터중 일부를 열어본다.
seoul = pd.read_csv('C:\\Users\\X1Carbon\\Desktop\\python\\data\\소상공인시장상권정보_20211231-20220719T055737Z-001\\소상공인시장진흥공단_상가(상권)정보_20211231\\소상공인시장진흥공단_상가(상권)정보_서울_202112.csv')
seoul
```

```python
# base_path를 지정하고 
base_path = 'C:\\Users\\X1Carbon\\Desktop\\python\\data\\소상공인시장상권정보_20211231-20220719T055737Z-001\\소상공인시장진흥공단_상가(상권)정보_20211231\\'
# glob() 함수를 통해 csv를 병합해보자
# glov 함수는 사용자가 제시한 조건에 맞는 파일명을 
# 리스트 형식으로 반환한다.
# data 폴더에 있는 모든 csv 파일을 읽어오기 위해 glob을 사용한다.
file_names = glob(base_path + '*.csv') # csv 확장자를 가지는 모든 파일 경로

# csv 목록 불러오기

# 모든 csv 병합하기
total_df = pd.DataFrame()

for file_name in file_names:
    temp_df = pd.read_csv(file_name)
    total_df = pd.concat([total_df, temp_df])
# reset index
total_df = total_df.reset_index(drop = True)
```

```python
# 분석에 필요한 column을 골라보자.
# 일단 각각의 column에 어떤 값이 있는지 알아보자 
total_df.columns # ['상권업종중분류명','상호명','시도명']
>>>
Index(['상가업소번호', '상호명', '지점명', '상권업종대분류코드', '상권업종대분류명', '상권업종중분류코드',
       '상권업종중분류명', '상권업종소분류코드', '상권업종소분류명', '표준산업분류코드', '표준산업분류명', '시도코드',
       '시도명', '시군구코드', '시군구명', '행정동코드', '행정동명', '법정동코드', '법정동명', '지번코드',
       '대지구분코드', '대지구분명', '지번본번지', '지번부번지', '지번주소', '도로명코드', '도로명', '건물본번지',
       '건물부번지', '건물관리번호', '건물명', '도로명주소', '구우편번호', '신우편번호', '동정보', '층정보',
       '호정보', '경도', '위도'],
      dtype='object')
------------------------------------------------------------
total_df.상권업종대분류명.unique()
>>>
array(['소매', '숙박', '학문/교육', '음식', '생활서비스', '부동산', '관광/여가/오락', '스포츠'],
      dtype=object)

------------------------------------------------------------
total_df.상권업종중분류명.unique() # --> '커피점/카페'
>>>
array(['자동차/자동차용품', '호텔/콘도', '가구소매', '학원기타', '유흥주점', '철물/난방/건설자재소매',
       '주유소/충전소', '가방/신발/액세서리', '가정/주방/인테리어', '커피점/카페', '한식', '화장품소매',
       ... (중략)

------------------------------------------------------------
total_df.상권업종소분류명.unique() # --> '상호명, 시도명'
>>>
array(['타이어판매', '호텔/콘도', '일반가구소매', '학원(종합)', '호프/맥주', '기타일반유흥주점',
       '보일러/냉난방용품', '셔터/새시판매', '차량가스충전소', '양품점', '정수기연수기', '커피전문점/카페/다방',
        ... (중략)
------------------------------------------------------------
total_df.시도명.unique()
>>>
array(['강원도', '경기도', '경상남도', '경상북도', '광주광역시', '대구광역시', '대전광역시', '부산광역시',
       '서울특별시', '세종특별자치시', '울산광역시', '인천광역시', '전라남도', '전라북도', '제주특별자치도',
       '충청남도', '충청북도'], dtype=object)

------------------------------------------------------------
# 메모리 낭비를 막기 위해 필요없는 변수는 제거한다.
temp_df = total_df[['상권업종중분류명','상호명','시도명']]
# total_df를 지우면 메모리를 아낄 수 있다.
del total_df
```

### **(2) 데이터 구경하기**

- **(2)-1. 전국 커피 전문점**
    
    ```python
    temp_df
    ```
    
    ![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2028.jpg)
    
    ```python
    # 카페만 뽑아내보자
    df_coffee = temp_df.loc[temp_df.상권업종중분류명 == '커피점/카페', :].reset_index(drop = True)
    # 위와 같이 정의하면 index가 섞이기 때문에 index를 다시 세팅한다.
    
    print("전국 커피 전문점 점포 수 : ", len(df_coffee))
    df_coffee.head()
    ```
    
    ![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2029.jpg)
    
- **(2)-2. 서울내 커피 전문점**
    
    ```python
    # 카페 중에 "서울"에 위치하고 있는 점포만 뽑아낸다.
    df_seoul_coffee = df_coffee.loc[df_coffee.시도명 == '서울특별시', :]
    df_seoul_coffee.index = range(len(df_seoul_coffee)) # reset_index와 같은 효과
    # df seoul coffee index를 range 함수를 써서 길이로 만들어 overwrite 해주는 것
    print('서울시 내 커피 전문점 점포 수 :', len(df_seoul_coffee))
    df_seoul_coffee.head()
    ```
    
    ![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2030.jpg)
    

***위와 같은 방법으로 (전국 스타벅스, 서울 스타벅스), (전국 이디야, 서울 이디야), (전국 투썸플레이스, 서울 투썸플레이스)를 구한다.***

### **(3) 커피전문점 별 비율 비교하기(주요 브랜드 위주로)**

**변수**

- 전체 점포 : temp_df
- 전체/서울 커피전문점 : df_coffee / df_seoul_coffee
- 전체/서울 스타벅스 : df_starbucks / df_seoul_starbucks
- 전체/서울 이디야 : df_ediya / df_seoul_ediya
- 전체/서울 투썸플레이스 : df_2some / df_seoul_2some
- (optional)전체/서울 빽다방 : df_bbaek / df_seoul_bbaek

<aside>
✅ **(3)-1. 전체 커피전문점 내 주요 커피브랜드 입점 비율**

```python
print("**** 전국 커피전문점중 주요 3대 커피브랜드 입점 비율 ****")
major_cafe_rate = (len(df_starbucks) + len(df_ediya) + len(df_2some)) / len(df_coffee)
print('%.2f%%' % (major_cafe_rate * 100))
>>>
**** 전국 커피전문점중 주요 3대 커피브랜드 입점 비율 ****
4.54%
```

</aside>

<aside>
✅ **(3)-2. 서울 커피전문점 내 주요 커피브랜드 입점 비율**

```python
print("스타벅스 : %.3f%%" % (len(df_seoul_starbucks) / len(df_seoul_coffee)*100))
print("이디야 : %.3f%%" % (len(df_seoul_ediya) / len(df_seoul_coffee)*100))
print("투썸플레이스 : %.3f%%" % (len(df_seoul_2some) / len(df_seoul_coffee)*100))
>>>
스타벅스 : 2.507%
이디야 : 2.212%
투썸플레이스 : 1.294%
```

</aside>

<aside>
✅ **(3)-3. 각 커피브랜드별 서울 입점 비율**

```python
print("**** 주요 커피브랜드별 서울 입점 비율 ****")
print("스타벅스 : %.3f%%" % (len(df_seoul_starbucks) / len(df_starbucks)*100))
print("이디야 : %.3f%%" % (len(df_seoul_ediya) / len(df_ediya)*100))
print("투썸플레이스 : %.3f%%" % (len(df_seoul_2some) / len(df_2some)*100))
>>>
**** 주요 커피브랜드별 서울 입점 비율 ****
스타벅스 : 31.071%
이디야 : 19.952%
투썸플레이스 : 23.218%
```

</aside>

<aside>
✅ **(3)-4. 주요 3대 커피브랜드 서울 입점 비율을 시각화 함**

```python
# 주요 3대 커피브랜드 서울 입점 비율을 시각화해보자!.
top3_cafe = pd.DataFrame({"coffee_brand": ['Starbucks', '2_Some_place', 'Ediya'],
                         "Ratio for those Cafe in Seoul(%)": [31.071, 19.952, 23.218]})
plt.figure(figsize = (8, 6))
sns.barplot(data = top3_cafe, x = 'coffee_brand', y = 'Ratio for those Cafe in Seoul(%)', palette = 'Set2')
plt.show()
```

![제목 없음.jpg](7%2019(Tue)%20Python%20Day%2010(Online)(EDA%20Practices)%20e334d0e724524b36bb6a8c351e8b2a36/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C%2031.jpg)

</aside>